{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.ensemble import IsolationForest \n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs = pd.read_csv(r'C:\\Users\\IknaShillingford\\Downloads\\acs5yr2010_cook.csv') \n",
    "mapping = pd.read_excel('C:\\\\Users\\\\IknaShillingford\\\\Downloads\\\\il17trf.xlsx', sheet_name='il17trf')\n",
    "energy = pd.read_csv(r'C:\\Users\\IknaShillingford\\Downloads\\energy_chicago.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs['GEO_ID'] = acs.GEO_ID.str.rsplit('US',expand=True)[1]\n",
    "acs = pd.merge(acs, mapping[['GEOID10','AREALANDPT']], how='left', left_on= acs['GEO_ID'], right_on= mapping['GEOID10'].astype('str'))\n",
    "acs['GEOID10'].isna().sum()\n",
    "\n",
    "energy['GEO_ID_TRACT'] = energy['CENSUS BLOCK'].astype('str').str[:11]\n",
    "e_tot = energy.groupby(['COMMUNITY AREA NAME','GEO_ID_TRACT'])[['TOTAL KWH','TOTAL THERMS']].sum()\n",
    "\n",
    "df = acs.merge(e_tot, how='right', right_on='GEO_ID_TRACT', left_on='GEO_ID')\n",
    "df['GEOID10'].isna().sum()\n",
    "df.drop(columns=['key_0','Unnamed: 0'], inplace=True)\n",
    "df.to_csv('acs_energy.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "y1 = df['TOTAL KWH']\n",
    "y2 = df['TOTAL THERMS']\n",
    "drop_cols = [0,1,2,3,4,-1,-2,-4]\n",
    "X = df.drop(df.columns[drop_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Missing Values:\n",
      "Estimate!!BEDROOMS!!1 bedroom                          0\n",
      "Estimate!!BEDROOMS!!2 bedrooms                         0\n",
      "Estimate!!BEDROOMS!!3 bedrooms                         0\n",
      "Estimate!!BEDROOMS!!4 bedrooms                         0\n",
      "Estimate!!BEDROOMS!!5 or more bedrooms                 0\n",
      "                                                      ..\n",
      "Estimate!!YEAR STRUCTURE BUILT!!Built 1990 to 1999     0\n",
      "Estimate!!YEAR STRUCTURE BUILT!!Built 2000 to 2004     0\n",
      "Estimate!!YEAR STRUCTURE BUILT!!Built 2005 or later    0\n",
      "Estimate!!YEAR STRUCTURE BUILT!!Total housing units    0\n",
      "AREALANDPT                                             0\n",
      "Length: 218, dtype: int64\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1015 entries, 0 to 1014\n",
      "Columns: 218 entries, Estimate!!BEDROOMS!!1 bedroom to AREALANDPT\n",
      "dtypes: float64(19), int64(199)\n",
      "memory usage: 1.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "missing_values = X.isna().sum()\n",
    "columns_with_missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "# Print the columns with missing values along with the number of missing values\n",
    "print(\"Columns with missing values:\")\n",
    "print(columns_with_missing_values)\n",
    "\n",
    "params = dict()\n",
    "params[\"device\"] = \"cuda\"\n",
    "np.int = np.int32\n",
    "np.float = np.float64\n",
    "np.bool = np.bool_\n",
    "\n",
    "\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(X.isnull().sum())\n",
    "\n",
    "# Get summary information about the DataFrame\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(X.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.reset_index(drop=True, inplace=True)\n",
    "y1.reset_index(drop=True, inplace=True)\n",
    "y2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Replace the '!' characters in column names with underscores\n",
    "X.columns = X.columns.str.replace('!', '_')\n",
    "X.columns = X.columns.str.replace('Estimate__', '')\n",
    "#X.columns = X.columns.str.replace(' ', '')\n",
    "# Check the modified column names\n",
    "print(X.columns)\n",
    "\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "#Feature selection based on electricity consumption as target variable\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=6, params=params)\n",
    "boruta_selector = BorutaPy(xgb, n_estimators='auto', verbose=2, random_state=6, perc=85)\n",
    "boruta_selector.fit(X.to_numpy(), y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output feature selection results\n",
    "feature_names = X.columns\n",
    "feature_ranks = list(zip(feature_names, boruta_selector.ranking_, boruta_selector.support_, boruta_selector.support_weak_ )) \n",
    "boruta_results_1 = pd.DataFrame(feature_ranks, columns=['feature_name','rank', 'confirmed','tentative'])\n",
    "\n",
    "#Feature selection based on electricity consumption as target variable\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=6, params=params)\n",
    "boruta_selector = BorutaPy(xgb, n_estimators='auto', verbose=2, random_state=6, perc=85)\n",
    "boruta_selector.fit(X.to_numpy(), y1)\n",
    "\n",
    "#output feature selection results (electricity as target variable)\n",
    "feature_names = X.columns\n",
    "feature_ranks = list(zip(feature_names, boruta_selector.ranking_, boruta_selector.support_, boruta_selector.support_weak_ )) \n",
    "boruta_results_2 = pd.DataFrame(feature_ranks, columns=['feature_name','rank', 'confirmed','tentative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features to keep based on Boruta results\n",
    "features_to_keep = boruta_results_1[(boruta_results_1['confirmed'] == True) | (boruta_results_1['tentative'] == True)]['feature_name'].tolist()\n",
    "# Filter the DataFrame to keep only the selected features\n",
    "df_filtered = X[features_to_keep]\n",
    "\n",
    "# Now 'df_filtered' contains only the features selected by Boruta (confirmed or tentative)\n",
    "df_filtered['TOTAL KWH'] = y1 \n",
    "#df_filtered['TOTAL THERMS'] = y2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "Xs = df_filtered.drop(['TOTAL KWH'], axis=1)  # Assuming 'TOTAL KWH' is the target variable\n",
    "ys = df_filtered['TOTAL KWH']\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, ys, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a dictionary to store MSE for each model\n",
    "mse_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "mse_dict['Linear Regression'] = mse_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "mse_dict['Ridge Regression'] = mse_ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IknaShillingford\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e+16, tolerance: 8.866e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and evaluate Lasso Regression\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "mse_dict['Lasso Regression'] = mse_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Decision Tree\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "mse_dict['Decision Tree'] = mse_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Random Forest\n",
    "forest_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_model.fit(X_train, y_train)\n",
    "y_pred_forest = forest_model.predict(X_test)\n",
    "mse_forest = mean_squared_error(y_test, y_pred_forest)\n",
    "mse_dict['Random Forest'] = mse_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "mse_dict['Gradient Boosting'] = mse_gb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate XGBoost\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "mse_dict['XGBoost'] = mse_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: XGBoost\n",
      "Best Mean Squared Error: 21817268597751.01\n"
     ]
    }
   ],
   "source": [
    "best_model = min(mse_dict, key=mse_dict.get)\n",
    "best_mse = mse_dict[best_model]\n",
    "print(f'Best Model: {best_model}')\n",
    "print(f'Best Mean Squared Error: {best_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Best XGBoost after Hyperparameter Tuning): 18641497495918.99\n",
      "Best Hyperparameters: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.2, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define XGBoost regressor model\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Define hyperparameters for grid search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Perform grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator from grid search\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict energy usage for test data using the best model\n",
    "y_pred_best_xgb = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "mse_best_xgb = mean_squared_error(y_test, y_pred_best_xgb)\n",
    "print('Mean Squared Error (Best XGBoost after Hyperparameter Tuning):', mse_best_xgb)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best Hyperparameters:', grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model to a file\n",
    "import joblib\n",
    "joblib.dump(best_xgb_model, 'best_xgb_model.pkl')\n",
    "\n",
    "# Load the model from the file\n",
    "loaded_model = joblib.load('best_xgb_model.pkl')\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "#predictions = loaded_model.predict(new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
